哈希函数可以将满足要求的任意长度的输入经过变换后得到固定长度的输出。这个固定长度的输出称为原消息的散列或消息摘要（Message Digest）。哈希函数的数学表述为：

                                    h=H(m)

    其中，H是哈希函数，m是任意长度明文，h是固定长度的哈希值。


 哈希函数有以下特点：

    ①压缩。对于任意大小的输入x，哈希值H（x）的长度很小，实际应用中哈希函数H产生的哈希值是固定长度。

    ②易计算。对于任意给定的消息，容易技术其哈希值。

    ③单向性。对于给定的哈希值h，要找到m'使得H(m')=h在计算上是不可行的，即求哈希的逆很困难。

    ④抗碰撞性。理想的哈希函数是无碰撞的，但实际算法设计中很难做到。有两种抗碰撞性：一种是弱抗碰撞性，即对于给定的消息x，
    要发现另一个消息y，满足H(x)=H(y)在计算上不可行；另一种是强抗碰撞性，即对于任意一对不同的消息（x,y），使得H(x)=H(y)在计算上不可行。

    ⑤高灵敏性。当一个输入位发生变化时，输出位将有一半以上会发生变化。




Hash:
数据快速查找，加密领域
将一个大的数据集映射到一个小的数据集上，这些
小的数据集叫hash value。
Hash Table:
根据key value pair 而直接进行访问的数据结构
通过把hash value 映射到hash表中的一个位置来访问
记录,以加快查找速度。

Hash Function:
1.如果两个hash value 不相同，那么这两个hash value的原始
输入也不相同
2. hash function的输入输出不是唯一对应关系，
如果两个hash value相同，两个输入值可能相同也可能不相同
这种情况称为hash collision.


常用的构造散列函数的方法:
1）直接寻址法：取关键字或关键字的某个线性函数值为散列地址。即H(key)=key或H(key) = a·key + b，其中a和b为常数（这种散列函数叫做自身函数）。
若其中H(key）中已经有值了，就往下一个找，直到H(key）中没有值了，就放进去。

2）数字分析法：分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，
这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构成散列地址，则冲突的几率会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。

3）平方取中法：当无法确定关键字中哪几位分布较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为哈希地址。
这是因为：平方后中间几位和关键字中每一位都相关，故不同关键字会以较高的概率产生不同的哈希地址。

4）折叠法：将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（去除进位）作为散列地址。
数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐，然后相加；间界叠加是从一端向另一端沿分割界来回折叠，然后对齐相加。

5） 随机数法：选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。

6） 除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。

即 H(key) = key MOD p,p<=m。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生同义词。


影响产生冲突多少有以下三个因素：

1. 散列函数是否均匀；
2. 处理冲突的方法；
3. 散列表的装填因子。

Hash算法的时间复杂度
    无冲突的hash table复杂度是O(1)，一般是O(c)，c为哈希关键字冲突时查找的平均长度，最坏情况仍然是O(N)。


Hash算法在信息安全方面的应用主要体现在以下的3个方面：

⑴ 文件校验
我们比较熟悉的校验算法有奇偶校验和CRC校验，这2种校验并没有抗数据篡改的能力，它们一定程度上能检测出数据传输中的信道误码，但却不能防止对数据的恶意破坏。
MD5 Hash算法的"数字指纹"特性，使它成为目前应用最广泛的一种文件完整性校验和（Checksum）算法，不少Unix系统有提供计算md5 checksum的命令。

⑵ 数字签名
Hash 算法也是现代密码体系中的一个重要组成部分。由于非对称算法的运算速度较慢，所以在数字签名协议中，单向散列函数扮演了一个重要的角色。对 Hash 值，又称"数字摘要"进行数字签名，在统计上可以认为与对文件本身进行数字签名是等效的。而且这样的协议还有其他的优点。

⑶ 鉴权协议
如下的鉴权协议又被称作挑战--认证模式：在传输信道是可被侦听，但不可被篡改的情况下，这是一种简单而安全的方法。
MD5、SHA1的破解


2、Hash Table法 
　　在第1个方法中，我们采用了排序的办法来统计每个Query出现的次数，时间复杂度是O(nlogn)，那么能不能有更好的方法来存储，而时间复杂度更低呢？
 　　题目中说明了，虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query 255Byte，因此我们可以考虑把他们都放进内存中去，而现在只是需要一个合适的数据结构，
 在这里，Hash Table绝对是我们优先的选择，因为Hash Table的查询速度非常的快，几乎是O(1)的时间复杂度。
 　　那么，我们的算法就有了：维护一个Key为Query字串，Value为该Query出现次数的HashTable，每次读取一个Query，如果该字串不在Table中，那么加入该字串，
 并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(n)的时间复杂度内完成了对该海量数据的处理。
 　　本方法相比算法1：在时间复杂度上提高了一个数量级，为O(n)，但不仅仅是时间复杂度上的优化，该方法只需要IO数据文件一次，而算法1的IO次数较多的，因此该算法2比算法1在工程上有更好的可操作性。
第二步：找出Top 10
        算法一：普通排序 
    我想对于排序算法大家都已经不陌生了，这里不在赘述，我们要注意的是排序算法的时间复杂度是O(nlogn)，在本题目中，三百万条记录，用1G内存是可以存下的。
 
　　算法二：部分排序 
　　题目要求是求出Top 10，因此我们没有必要对所有的Query都进行排序，我们只需要维护一个10个大小的数组，初始化放入10个Query，按照每个Query的统计次数由大到小排序，
然后遍历这300万条记录，每读一条记录就和数组最后一个Query对比，如果小于这个Query，那么继续遍历，否则，将数组中最后一条数据淘汰，加入当前的Query。最后当所有的数据都遍历完毕之后，那么这个数组中的10个Query便是我们要找的Top10了。
　　不难分析出，这样，算法的最坏时间复杂度是N*K， 其中K是指top多少。
 
　　算法三：堆 
　　在算法二中，我们已经将时间复杂度由NlogN优化到NK，不得不说这是一个比较大的改进了，可是有没有更好的办法呢？
 　　分析一下，在算法二中，每次比较完成之后，需要的操作复杂度都是K，因为要把元素插入到一个线性表之中，而且采用的是顺序比较。这里我们注意一下，该数组是有序的，
 一次我们每次查找的时候可以采用二分的方法查找，这样操作的复杂度就降到了logK，可是，随之而来的问题就是数据移动，因为移动数据次数增多了。不过，这个算法还是比算法二有了改进。
 　　基于以上的分析，我们想想，有没有一种既能快速查找，又能快速移动元素的数据结构呢？回答是肯定的，那就是堆。
 　　借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此到这里，我们的算法可以改进为这样，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。
　　思想与上述算法二一致，只是算法在算法三，我们采用了最小堆这种数据结构代替数组，把查找目标元素的时间复杂度有O(K)降到了O(logK)。
 　　那么这样，采用堆数据结构，算法三，最终的时间复杂度就降到了N‘logK，和算法二相比，又有了比较大的改进。 
 　　
 总结：
 　　至此，算法就完全结束了，经过上述第一步、先用Hash表统计每个Query出现的次数，O(N)；然后第二步、采用堆数据结构找出Top 10，N*O(logK)。所以，我们最终的时间复杂度是：O(N)+N'*O(logK)。（N为1000万，N’为300万）